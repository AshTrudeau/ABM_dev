# this is the submit file
# abm-model-run.sub


# Specify the HTCondor Universe (vanilla is the default and is used
#  for almost all jobs) and your desired name of the HTCondor log file,
#  which is where HTCondor will describe what steps it takes to run 
#  your job. Wherever you see $(Cluster), HTCondor will insert the 
#  queue number assigned to this set of jobs at the time of submission.
universe = vanilla
log = abm-model-run_$(Cluster).log
#initialdir = ABM_dev
preserve_relative_paths = 1
#
# Specify your executable (single binary or a script that runs several
#  commands), arguments, and a files for HTCondor to store standard
#  output (or "screen output").
#  $(Process) will be a integer number for each job, starting with "0"
#  and increasing for the relevant number of jobs.
executable = run_R.sh
arguments = $(Process) annual.output.csv lake.status.csv
output = abm-model-run_$(Cluster)_$(Process).out
error = abm-model-run_$(Cluster)_$(Process).err
# Specify that HTCondor should transfer files to and from the
#  computer where each job runs. The last of these lines *would* be
#  used if there were any other files needed for the executable to use.
should_transfer_files = YES
when_to_transfer_output = ON_EXIT

transfer_input_files = http://proxy.chtc.wisc.edu/SQUID/chtc/el8/R413.tar.gz, \
  packages.tar.gz, \
  run.model.walleye.pop.constantM.R, \
  data, source, output
  
#
# Tell HTCondor what amount of compute resources
#  each job will need on the computer where it runs.
request_cpus = 1
request_memory = 5GB
request_disk = 5GB
#
# Tell HTCondor to run however many instances of our job:
queue 1
#
